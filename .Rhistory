svm.fit = svm(y~., data=dat, kernel='linear', cost=costs[i])
svm.pred = predict(svm.fit, newdata=dat.test)
mat = table(pred=svm.pred, actual=ytest)
err.test[i] = (mat[1, 2]+mat[2, 1])/sum(mat)
}
plot(costs, err.test, type='b', xlab='cost', ylab='test error')
# cost = 0.1 leads to the smallest test error
set.seed(1e3)
xtest = matrix(runif(n*p), ncol=p)
ytest = ifelse(x[, 1]+x[, 2]>1, 1, 0)
dat.test = data.frame(x=xtest, y=ytest)
err.test = rep(0, length(costs))
for(i in 1:length(costs)){
svm.fit = svm(y~., data=dat, kernel='linear', cost=costs[i])
svm.pred = predict(svm.fit, newdata=dat.test)
mat = table(pred=svm.pred, actual=ytest)
err.test[i] = (mat[1, 2]+mat[2, 1])/sum(mat)
}
plot(costs, err.test, type='b', xlab='cost', ylab='test error')
# cost = 0.1 leads to the smallest test error
set.seed(100)
xtest = matrix(runif(n*p), ncol=p)
ytest = ifelse(x[, 1]+x[, 2]>1, 1, 0)
dat.test = data.frame(x=xtest, y=ytest)
err.test = rep(0, length(costs))
for(i in 1:length(costs)){
svm.fit = svm(y~., data=dat, kernel='linear', cost=costs[i])
svm.pred = predict(svm.fit, newdata=dat.test)
mat = table(pred=svm.pred, actual=ytest)
err.test[i] = (mat[1, 2]+mat[2, 1])/sum(mat)
}
plot(costs, err.test, type='b', xlab='cost', ylab='test error')
# cost = 0.1 leads to the smallest test error
set.seed(1001)
xtest = matrix(runif(n*p), ncol=p)
ytest = ifelse(x[, 1]+x[, 2]>1, 1, 0)
dat.test = data.frame(x=xtest, y=ytest)
err.test = rep(0, length(costs))
for(i in 1:length(costs)){
svm.fit = svm(y~., data=dat, kernel='linear', cost=costs[i])
svm.pred = predict(svm.fit, newdata=dat.test)
mat = table(pred=svm.pred, actual=ytest)
err.test[i] = (mat[1, 2]+mat[2, 1])/sum(mat)
}
plot(costs, err.test, type='b', xlab='cost', ylab='test error')
# cost = 0.1 leads to the smallest test error
set.seed(1002)
xtest = matrix(runif(n*p), ncol=p)
ytest = ifelse(x[, 1]+x[, 2]>1, 1, 0)
dat.test = data.frame(x=xtest, y=ytest)
err.test = rep(0, length(costs))
for(i in 1:length(costs)){
svm.fit = svm(y~., data=dat, kernel='linear', cost=costs[i])
svm.pred = predict(svm.fit, newdata=dat.test)
mat = table(pred=svm.pred, actual=ytest)
err.test[i] = (mat[1, 2]+mat[2, 1])/sum(mat)
}
plot(costs, err.test, type='b', xlab='cost', ylab='test error')
# cost = 0.1 leads to the smallest test error
set.seed(1003)
xtest = matrix(runif(n*p), ncol=p)
ytest = ifelse(x[, 1]+x[, 2]>1, 1, 0)
dat.test = data.frame(x=xtest, y=ytest)
err.test = rep(0, length(costs))
for(i in 1:length(costs)){
svm.fit = svm(y~., data=dat, kernel='linear', cost=costs[i])
svm.pred = predict(svm.fit, newdata=dat.test)
mat = table(pred=svm.pred, actual=ytest)
err.test[i] = (mat[1, 2]+mat[2, 1])/sum(mat)
}
plot(costs, err.test, type='b', xlab='cost', ylab='test error')
# cost = 0.1 leads to the smallest test error
set.seed(1003)
xtest = matrix(runif(n*p), ncol=p)
ytest = ifelse(x[, 1]+x[, 2]>1, 1, 0)
dat.test = data.frame(x=xtest, y=ytest)
err.test = rep(0, length(costs))
for(i in 1:length(costs)){
svm.fit = svm(y~., data=dat, kernel='linear', cost=costs[i])
svm.pred = predict(svm.fit, newdata=dat.test)
mat = table(pred=svm.pred, actual=ytest)
err.test[i] = (mat[1, 2]+mat[2, 1])/sum(mat)
}
plot(costs, err.test, type='b', xlab='cost', ylab='test error')
# cost = 0.1 leads to the smallest test error
which.min(err.test)
costs[4]
which.min(err.cv)
costs[3]
set.seed(1e4)
xtest = matrix(runif(n*p), ncol=p)
ytest = ifelse(x[, 1]+x[, 2]>1, 1, 0)
dat.test = data.frame(x=xtest, y=ytest)
err.test = rep(0, length(costs))
for(i in 1:length(costs)){
svm.fit = svm(y~., data=dat, kernel='linear', cost=costs[i])
svm.pred = predict(svm.fit, newdata=dat.test)
mat = table(pred=svm.pred, actual=ytest)
err.test[i] = (mat[1, 2]+mat[2, 1])/sum(mat)
}
plot(costs, err.test, type='b', xlab='cost', ylab='test error')
# cost = 5 leads to the smallest test error
# this is larger than
set.seed(1e5)
xtest = matrix(runif(n*p), ncol=p)
ytest = ifelse(x[, 1]+x[, 2]>1, 1, 0)
dat.test = data.frame(x=xtest, y=ytest)
err.test = rep(0, length(costs))
for(i in 1:length(costs)){
svm.fit = svm(y~., data=dat, kernel='linear', cost=costs[i])
svm.pred = predict(svm.fit, newdata=dat.test)
mat = table(pred=svm.pred, actual=ytest)
err.test[i] = (mat[1, 2]+mat[2, 1])/sum(mat)
}
plot(costs, err.test, type='b', xlab='cost', ylab='test error')
# cost = 5 leads to the smallest test error
# this is larger than
set.seed(1e6)
xtest = matrix(runif(n*p), ncol=p)
ytest = ifelse(x[, 1]+x[, 2]>1, 1, 0)
dat.test = data.frame(x=xtest, y=ytest)
err.test = rep(0, length(costs))
for(i in 1:length(costs)){
svm.fit = svm(y~., data=dat, kernel='linear', cost=costs[i])
svm.pred = predict(svm.fit, newdata=dat.test)
mat = table(pred=svm.pred, actual=ytest)
err.test[i] = (mat[1, 2]+mat[2, 1])/sum(mat)
}
plot(costs, err.test, type='b', xlab='cost', ylab='test error')
# cost = 5 leads to the smallest test error
# this is larger than
set.seed(1e7)
xtest = matrix(runif(n*p), ncol=p)
ytest = ifelse(x[, 1]+x[, 2]>1, 1, 0)
dat.test = data.frame(x=xtest, y=ytest)
err.test = rep(0, length(costs))
for(i in 1:length(costs)){
svm.fit = svm(y~., data=dat, kernel='linear', cost=costs[i])
svm.pred = predict(svm.fit, newdata=dat.test)
mat = table(pred=svm.pred, actual=ytest)
err.test[i] = (mat[1, 2]+mat[2, 1])/sum(mat)
}
plot(costs, err.test, type='b', xlab='cost', ylab='test error')
# cost = 5 leads to the smallest test error
# this is larger than
set.seed(1e8)
xtest = matrix(runif(n*p), ncol=p)
ytest = ifelse(x[, 1]+x[, 2]>1, 1, 0)
dat.test = data.frame(x=xtest, y=ytest)
err.test = rep(0, length(costs))
for(i in 1:length(costs)){
svm.fit = svm(y~., data=dat, kernel='linear', cost=costs[i])
svm.pred = predict(svm.fit, newdata=dat.test)
mat = table(pred=svm.pred, actual=ytest)
err.test[i] = (mat[1, 2]+mat[2, 1])/sum(mat)
}
plot(costs, err.test, type='b', xlab='cost', ylab='test error')
# cost = 5 leads to the smallest test error
# this is larger than
set.seed(5)
xtest = matrix(runif(n*p), ncol=p)
ytest = ifelse(x[, 1]+x[, 2]>1, 1, 0)
dat.test = data.frame(x=xtest, y=ytest)
err.test = rep(0, length(costs))
for(i in 1:length(costs)){
svm.fit = svm(y~., data=dat, kernel='linear', cost=costs[i])
svm.pred = predict(svm.fit, newdata=dat.test)
mat = table(pred=svm.pred, actual=ytest)
err.test[i] = (mat[1, 2]+mat[2, 1])/sum(mat)
}
plot(costs, err.test, type='b', xlab='cost', ylab='test error')
# cost = 5 leads to the smallest test error
# this is larger than
set.seed(6)
xtest = matrix(runif(n*p), ncol=p)
ytest = ifelse(x[, 1]+x[, 2]>1, 1, 0)
dat.test = data.frame(x=xtest, y=ytest)
err.test = rep(0, length(costs))
for(i in 1:length(costs)){
svm.fit = svm(y~., data=dat, kernel='linear', cost=costs[i])
svm.pred = predict(svm.fit, newdata=dat.test)
mat = table(pred=svm.pred, actual=ytest)
err.test[i] = (mat[1, 2]+mat[2, 1])/sum(mat)
}
plot(costs, err.test, type='b', xlab='cost', ylab='test error')
# cost = 5 leads to the smallest test error
# this is larger than
set.seed(9)
xtest = matrix(runif(n*p), ncol=p)
ytest = ifelse(x[, 1]+x[, 2]>1, 1, 0)
dat.test = data.frame(x=xtest, y=ytest)
err.test = rep(0, length(costs))
for(i in 1:length(costs)){
svm.fit = svm(y~., data=dat, kernel='linear', cost=costs[i])
svm.pred = predict(svm.fit, newdata=dat.test)
mat = table(pred=svm.pred, actual=ytest)
err.test[i] = (mat[1, 2]+mat[2, 1])/sum(mat)
}
plot(costs, err.test, type='b', xlab='cost', ylab='test error')
# cost = 5 leads to the smallest test error
# this is larger than
which.min(err.test)
costs[2]
library(e1071)
library(ISLR)
attach(Auto)
set.seed(1)
# --------------------------- (a) ---------------------------
med = median(mpg)
library(e1071)
library(ISLR)
attach(Auto)
set.seed(1)
# --------------------------- (a) ---------------------------
med = median(mpg)
mpgMed = ifelse(mpg>med, 1, 0)
# --------------------------- (b) ---------------------------
Auto = cbind(Auto, mpgMed)
costs = c(0.01, 0.1, 1, 5, 10, 15, 20, 30, 50)
svm.linear.cv = tune(svm, mpgMed~.-mpg, data=Auto, kernel='linear', ranges=list(cost=costs))
err.cv = svm.linear.cv$performance$error
plot(costs, err.cv, type='b', xlab='cost', ylab='cross-validation error')
which.min(err.cv)
costs[3]
# SVM: polynomial kernel
dgs = 1:5
svm.poly.cv = tune(svm, mpgMed~.-mpg, data=Auto, kernel='polynomial', ranges=list(cost=costs, degree=dgs))
summary(svm.poly.cv)
install.packages("plotly")
svm.poly.cv$performances
library(plotly)
x = svm.poly.cv$performances$cost
y = svm.poly.cv$performances$degree
y = svm.poly.cv$performances$error
y = svm.poly.cv$performances$degree
z = svm.poly.cv$performances$degree
z = svm.poly.cv$performances$error
plot_ly(x=x, y=y, z=z) %>% add_markers()
svm.poly.cv
summary(svm.poly.cv)
# SVM: radial kernel
gms = costs
svm.radial.cv = tune(svm, mpgMed~.-mpg, data=Auto, kernel='radial', ranges=list(cost=costs, gamma=gms))
summary(svm.radial.cv)
View(Auto)
plot(svm.radial.cv$best.model, Auto, names(Auto)[2:9])
plot(svm.radial.cv$best.model, Auto, names(Auto)[2:9])
plot(svm.radial.cv$best.model, Auto)
library(e1071)
library(ISLR)
attach(Auto)
set.seed(1)
# --------------------------- (a) ---------------------------
med = median(mpg)
mpgMed = ifelse(mpg>med, 1, 0)
# --------------------------- (b) ---------------------------
Auto = cbind(Auto, mpgMed)
costs = c(0.01, 0.1, 1, 5, 10, 15, 20, 30, 50)
svm.linear.cv = tune(svm, mpgMed~.-mpg, data=Auto, kernel='linear', ranges=list(cost=costs))
err.cv = svm.linear.cv$performance$error
plot(costs, err.cv, type='b', xlab='cost', ylab='cross-validation error')
# cost = 1 leads to the lowest cross-validation error
# --------------------------- (c) ---------------------------
# SVM: polynomial kernel
dgs = 1:5
svm.poly.cv = tune(svm, mpgMed~.-mpg, data=Auto, kernel='polynomial', ranges=list(cost=costs, degree=dgs))
# best parameters are: cost=50, degree=1
# best cross-validation error is: 0.09921599
# SVM: radial kernel
gms = costs
svm.radial.cv = tune(svm, mpgMed~.-mpg, data=Auto, kernel='radial', ranges=list(cost=costs, gamma=gms))
# best parameters are: cost=5, gamma=0.1
# best cross-validation error is: 0.06294489
class(svm.radial.cv$best.model)
svm.radial.cv$best.model
View(Auto)
plot(svm.radial.cv$best.model, Auto,, c('cylinders', 'displacement', 'horsepower'))
plot(svm.radial.cv$best.model, Auto, cylinders~horsepower)
plot(svm.radial.cv$best.model, Auto, 'cylinders'~'horsepower')
plot(svm.radial.cv$best.model, Auto, as.formula('mpgMed~cylinders+displacement))
)
)
')
''
plot(svm.radial.cv$best.model, Auto, as.formula('mpgMed~cylinders+displacement'))
plot(svm.radial.cv$best.model, Auto, as.formula('mpgMed~cylinders'))
fit = svm.radial.cv$best.model
plot(fit, Auto, as.formula('mpgMed~cylinders'))
fit = svm(mpgMed~., data=Auto, kernel='radial', cost=5, gamma=0.1)
plot(fit, Auto, as.formula('mpgMed~cylinders'))
View(fit)
library(e1071)
library(ISLR)
attach(OJ)
set.seed(1)
idx.train = sample(nrow(OJ), 800)
train = OJ[idx.train, ]
test = OJ[-idx.train, ]
svm.linear = svm(Purchase~., data=train, kernel='linear', cost=0.01)
summary(svm.linear)
View(train)
err.train = (mat.train[1, 2] + mat.train[2, 1])/sum(mat.train)
# ------------------------ (c) ------------------------
mat.train = table(pred=svm.linear$fitted, actual=train$Purchase)
err.train = (mat.train[1, 2] + mat.train[2, 1])/sum(mat.train)
svm.linear.pred = predict(svm.linear, newdata=test)
mat.test = table(pred=svm.linear.pred, actual=test$Purchase)
err.test = (mat.test[1, 2] + mat.test[2, 1])/sum(mat.test)
# ------------------------ (d) ------------------------
costs = c(0.01, 0.1, 0.5, 1, 3, 5, 7, 10)
svm.linear.cv = tune(svm, Purchase~., data=train, kernel='linear', ranges=list(cost=costs))
summary(svm.linear.cv)
svm.linear.opt = svm.linear.cv$best.model
# ------------------------ (e) ------------------------
svm.linear.opt = svm.linear.cv$best.model
mat.opt.train = table(pred=svm.linear.opt$fitted, actual=train$Purchase)
err.opt.train = (mat.opt.train[1,2]+mat.opt.train[2,1])/sum(mat.opt.train)
svm.linear.opt.pred = predict(svm.linear.opt, newdata=test)
mat.opt.test = table(pred=svm.linear.opt.pred, actual=test$Purchase)
err.opt.test = ( mat.opt.test[1,2]+mat.opt.test[2,1] )/sum(mat.opt.test)
library(e1071)
library(ISLR)
attach(OJ)
set.seed(1)
# ------------------------ (a) ------------------------
idx.train = sample(nrow(OJ), 800)
train = OJ[idx.train, ]
test = OJ[-idx.train, ]
# ------------------------ (f) ------------------------
svm.radial = svm(Purchase~., data=train, kernel='radial', cost=0.01)
summary(svm.radial)
mat.train = table(pred=svm.radial$fitted, actual=train$Purchase)
err.train = (mat.train[1, 2] + mat.train[2, 1])/sum(mat.train)
# training error = 0.175
svm.radial.pred = predict(svm.radial, newdata=test)
mat.test = table(pred=svm.radial.pred, actual=test$Purchase)
err.test = (mat.test[1, 2] + mat.test[2, 1])/sum(mat.test)
# test error = 0.177778
costs = c(0.01, 0.1, 0.5, 1, 3, 5, 7, 10)
svm.radial.cv = tune(svm, Purchase~., data=train, kernel='radial', ranges=list(cost=costs))
summary(svm.radial.cv)
# optimal cost=7
svm.radial.opt = svm.radial.cv$best.model
mat.opt.train = table(pred=svm.radial.opt$fitted, actual=train$Purchase)
err.opt.train = (mat.opt.train[1,2]+mat.opt.train[2,1])/sum(mat.opt.train)
# training error = 0.1625
svm.radial.opt.pred = predict(svm.radial.opt, newdata=test)
mat.opt.test = table(pred=svm.radial.opt.pred, actual=test$Purchase)
err.opt.test = ( mat.opt.test[1,2]+mat.opt.test[2,1] )/sum(mat.opt.test)
# test error = 0.1519
library(e1071)
library(ISLR)
attach(OJ)
set.seed(1)
# ------------------------ (a) ------------------------
idx.train = sample(nrow(OJ), 800)
train = OJ[idx.train, ]
test = OJ[-idx.train, ]
# ------------------------ (g) ------------------------
svm.polynomial = svm(Purchase~., data=train, kernel='polynomial', cost=0.01)
summary(svm.polynomial)
mat.train = table(pred=svm.polynomial$fitted, actual=train$Purchase)
err.train = (mat.train[1, 2] + mat.train[2, 1])/sum(mat.train)
# training error = 0.39375
svm.polynomial.pred = predict(svm.polynomial, newdata=test)
mat.test = table(pred=svm.polynomial.pred, actual=test$Purchase)
err.test = (mat.test[1, 2] + mat.test[2, 1])/sum(mat.test)
# test error = 0.37778
costs = c(0.01, 0.1, 0.5, 1, 3, 5, 7, 10)
svm.polynomial.cv = tune(svm, Purchase~., data=train, kernel='polynomial', ranges=list(cost=costs))
summary(svm.polynomial.cv)
# optimal cost=0.5
svm.polynomial.opt = svm.polynomial.cv$best.model
mat.opt.train = table(pred=svm.polynomial.opt$fitted, actual=train$Purchase)
err.opt.train = (mat.opt.train[1,2]+mat.opt.train[2,1])/sum(mat.opt.train)
# training error = 0.1425
svm.polynomial.opt.pred = predict(svm.polynomial.opt, newdata=test)
mat.opt.test = table(pred=svm.polynomial.opt.pred, actual=test$Purchase)
err.opt.test = ( mat.opt.test[1,2]+mat.opt.test[2,1] )/sum(mat.opt.test)
# test error = 0.17778
library(e1071)
library(ISLR)
attach(OJ)
set.seed(1)
# ------------------------ (g) ------------------------
svm.polynomial = svm(Purchase~., data=train, kernel='polynomial', cost=0.01, degree=2)
summary(svm.polynomial)
mat.train = table(pred=svm.polynomial$fitted, actual=train$Purchase)
err.train = (mat.train[1, 2] + mat.train[2, 1])/sum(mat.train)
# training error = 0.37125
svm.polynomial.pred = predict(svm.polynomial, newdata=test)
mat.test = table(pred=svm.polynomial.pred, actual=test$Purchase)
err.test = (mat.test[1, 2] + mat.test[2, 1])/sum(mat.test)
# test error = 0.3630
costs = c(0.01, 0.1, 0.5, 1, 3, 5, 7, 10)
svm.polynomial.cv = tune(svm, Purchase~., data=train, kernel='polynomial', degree=2, ranges=list(cost=costs))
summary(svm.polynomial.cv)
# optimal cost=0.5
svm.polynomial.opt = svm.polynomial.cv$best.model
mat.opt.train = table(pred=svm.polynomial.opt$fitted, actual=train$Purchase)
err.opt.train = (mat.opt.train[1,2]+mat.opt.train[2,1])/sum(mat.opt.train)
# training error = 0.1425
svm.polynomial.opt.pred = predict(svm.polynomial.opt, newdata=test)
mat.opt.test = table(pred=svm.polynomial.opt.pred, actual=test$Purchase)
err.opt.test = ( mat.opt.test[1,2]+mat.opt.test[2,1] )/sum(mat.opt.test)
# test error = 0.17778
library(e1071)
library(ISLR)
attach(OJ)
set.seed(1)
# ------------------------ (a) ------------------------
idx.train = sample(nrow(OJ), 800)
train = OJ[idx.train, ]
test = OJ[-idx.train, ]
svm.polynomial = svm(Purchase~., data=train, kernel='polynomial', cost=0.01, degree=2)
summary(svm.polynomial)
mat.train = table(pred=svm.polynomial$fitted, actual=train$Purchase)
err.train = (mat.train[1, 2] + mat.train[2, 1])/sum(mat.train)
# training error = 0.37125
svm.polynomial.pred = predict(svm.polynomial, newdata=test)
mat.test = table(pred=svm.polynomial.pred, actual=test$Purchase)
err.test = (mat.test[1, 2] + mat.test[2, 1])/sum(mat.test)
# test error = 0.3630
costs = c(0.01, 0.1, 0.5, 1, 3, 5, 7, 10)
svm.polynomial.cv = tune(svm, Purchase~., data=train, kernel='polynomial', degree=2, ranges=list(cost=costs))
summary(svm.polynomial.cv)
# optimal cost=0.5
svm.polynomial.opt = svm.polynomial.cv$best.model
mat.opt.train = table(pred=svm.polynomial.opt$fitted, actual=train$Purchase)
err.opt.train = (mat.opt.train[1,2]+mat.opt.train[2,1])/sum(mat.opt.train)
# training error = 0.1425
svm.polynomial.opt.pred = predict(svm.polynomial.opt, newdata=test)
mat.opt.test = table(pred=svm.polynomial.opt.pred, actual=test$Purchase)
err.opt.test = ( mat.opt.test[1,2]+mat.opt.test[2,1] )/sum(mat.opt.test)
# test error = 0.17778
library(e1071)
library(ISLR)
attach(OJ)
set.seed(1)
# ------------------------ (a) ------------------------
idx.train = sample(nrow(OJ), 800)
train = OJ[idx.train, ]
test = OJ[-idx.train, ]
# ------------------------ (b) ------------------------
svm.linear = svm(Purchase~., data=train, kernel='linear', cost=0.01)
summary(svm.linear)
# ------------------------ (c) ------------------------
mat.train = table(pred=svm.linear$fitted, actual=train$Purchase)
err.train = (mat.train[1, 2] + mat.train[2, 1])/sum(mat.train)
# training error = 0.175
svm.linear.pred = predict(svm.linear, newdata=test)
mat.test = table(pred=svm.linear.pred, actual=test$Purchase)
err.test = (mat.test[1, 2] + mat.test[2, 1])/sum(mat.test)
# test error = 0.177778
# ------------------------ (d) ------------------------
costs = c(0.01, 0.1, 0.5, 1, 3, 5, 7, 10)
svm.linear.cv = tune(svm, Purchase~., data=train, kernel='linear', ranges=list(cost=costs))
summary(svm.linear.cv)
# optimal cost=7
# ------------------------ (e) ------------------------
svm.linear.opt = svm.linear.cv$best.model
mat.opt.train = table(pred=svm.linear.opt$fitted, actual=train$Purchase)
err.opt.train = (mat.opt.train[1,2]+mat.opt.train[2,1])/sum(mat.opt.train)
# training error = 0.1625
svm.linear.opt.pred = predict(svm.linear.opt, newdata=test)
mat.opt.test = table(pred=svm.linear.opt.pred, actual=test$Purchase)
err.opt.test = ( mat.opt.test[1,2]+mat.opt.test[2,1] )/sum(mat.opt.test)
# test error = 0.1519
# ------------------------ (f) ------------------------
svm.radial = svm(Purchase~., data=train, kernel='radial', cost=0.01)
summary(svm.radial)
mat.train = table(pred=svm.radial$fitted, actual=train$Purchase)
err.train = (mat.train[1, 2] + mat.train[2, 1])/sum(mat.train)
# training error = 0.39375
svm.radial.pred = predict(svm.radial, newdata=test)
mat.test = table(pred=svm.radial.pred, actual=test$Purchase)
err.test = (mat.test[1, 2] + mat.test[2, 1])/sum(mat.test)
# test error = 0.37778
costs = c(0.01, 0.1, 0.5, 1, 3, 5, 7, 10)
svm.radial.cv = tune(svm, Purchase~., data=train, kernel='radial', ranges=list(cost=costs))
summary(svm.radial.cv)
# optimal cost=0.5
svm.radial.opt = svm.radial.cv$best.model
mat.opt.train = table(pred=svm.radial.opt$fitted, actual=train$Purchase)
err.opt.train = (mat.opt.train[1,2]+mat.opt.train[2,1])/sum(mat.opt.train)
# training error = 0.1425
svm.radial.opt.pred = predict(svm.radial.opt, newdata=test)
mat.opt.test = table(pred=svm.radial.opt.pred, actual=test$Purchase)
err.opt.test = ( mat.opt.test[1,2]+mat.opt.test[2,1] )/sum(mat.opt.test)
# test error = 0.17778
# ------------------------ (g) ------------------------
svm.polynomial = svm(Purchase~., data=train, kernel='polynomial', cost=0.01, degree=2)
summary(svm.polynomial)
mat.train = table(pred=svm.polynomial$fitted, actual=train$Purchase)
err.train = (mat.train[1, 2] + mat.train[2, 1])/sum(mat.train)
# training error = 0.37125
svm.polynomial.pred = predict(svm.polynomial, newdata=test)
mat.test = table(pred=svm.polynomial.pred, actual=test$Purchase)
err.test = (mat.test[1, 2] + mat.test[2, 1])/sum(mat.test)
# test error = 0.36667
costs = c(0.01, 0.1, 0.5, 1, 3, 5, 7, 10)
svm.polynomial.cv = tune(svm, Purchase~., data=train, kernel='polynomial', degree=2, ranges=list(cost=costs))
summary(svm.polynomial.cv)
# optimal cost=3
svm.polynomial.opt = svm.polynomial.cv$best.model
mat.opt.train = table(pred=svm.polynomial.opt$fitted, actual=train$Purchase)
err.opt.train = (mat.opt.train[1,2]+mat.opt.train[2,1])/sum(mat.opt.train)
# training error = 0.15375
svm.polynomial.opt.pred = predict(svm.polynomial.opt, newdata=test)
mat.opt.test = table(pred=svm.polynomial.opt.pred, actual=test$Purchase)
err.opt.test = ( mat.opt.test[1,2]+mat.opt.test[2,1] )/sum(mat.opt.test)
# test error = 0.2037
