glm.prob = predict(glm.fit, newdata=Weekly[1, ], type='response')
glm.pred = if (glm.prob >= 0.5) 'Yes' else 'No'
typeof(glm.prob)
class(glm.prob)
glm.prob = predict(glm.fit, newdata=Weekly[1, ], type='response')
glm.pred = if (glm.prob >= 0.5) 'Yes' else 'No'
glm.prob = predict(glm.fit, newdata=Weekly[1:2, ], type='response')
glm.pred = if (glm.prob >= 0.5) 'Yes' else 'No'
glm.prob = predict(glm.fit, newdata=Weekly[1, ], type='response')
glm.pred = if (glm.prob >= 0.5) 'Yes' else 'No'
Weekly[1, ]$Direction
contrasts(Direction)
glm.prob = predict(glm.fit, newdata=Weekly[1, ], type='response')
glm.pred = if (glm.prob >= 0.5) 'Up' else 'Down'
n.obs = nrow(Weekly)
store = rep(NA, n.obs)
for (i in 1:n.obs){
glm.fit = glm(Direction~Lag1+Lag2, data=Weekly[-i, ], family=binomial)
glm.prob = predict(glm.fit, newdata=Weekly[i, ], type='response')
glm.pred = if (glm.prob >= 0.5) 'Up' else 'Down'
store[i] = (glm.pred == Weekly$Direction[i])
}
store
n.obs = nrow(Weekly)
store = rep(NA, n.obs)
for (i in 1:n.obs){
glm.fit = glm(Direction~Lag1+Lag2, data=Weekly[-i, ], family=binomial)
glm.prob = predict(glm.fit, newdata=Weekly[i, ], type='response')
glm.pred = if (glm.prob >= 0.5) 'Up' else 'Down'
store[i] = (glm.pred == Weekly$Direction[i]) * 1
}
mean(store)
glm.fit = glm(Direction~Lag1+Lag2, data=Weekly, family=binomial)
summary(glm.fit)
n.obs = nrow(Weekly)
store = rep(NA, n.obs)
for (i in 1:n.obs){
glm.fit = glm(Direction~Lag1+Lag2, data=Weekly[-i, ], family=binomial)
glm.prob = predict(glm.fit, newdata=Weekly[i, ], type='response')
glm.pred = if (glm.prob >= 0.5) 'Up' else 'Down'
store[i] = (glm.pred != Weekly$Direction[i]) * 1
}
mean(store)
# ************* Quetion 6 *************
library(boot)
library(ISLR)
attach(Default)
# (a)
glm.fit = glm(default~income+balance, data=Default, family=binomial)
summary(glm.fit)
# S.E. for income: 4.985e-06
# S.E. for balance: 2.274e-04
# (b)
boot.fn = function(data, index){
glm.fit = glm(default~income+balance, data=data, subset=index, family=binomial)
return( coef(glm.fit)[-1] )
}
# (c)
set.seed(1)
boot(Default, boot.fn, R=1000)
plot(x, y)
# (a)
set.seed(1)
y = rnorm(100)
x = rnorm(100)
y = x - 2*x^2 + rnorm(100)
# n = 100, p = 2
# the equation is: y = x - 2 * X^2 + eps
# (b)
plot(x, y)
df = data.frame(c(X, Y))
df = data.frame(c(x, y))
df = data.frame(x, y)
n.obs = nrow(df)
df = data.frame(x, y)
n.obs = nrow(df)
cv.err = rep(NA, 5)
set.seed(1)
for (i in 1:5) {
glm.fit = glm(y~poly(x, i, raw=T), data=df)
cv.err[i] = cv.glm(df, glm.fit, K=n.obs)$delta[1]
}
cv.err
set.seed(2)
for (i in 1:5) {
glm.fit = glm(y~poly(x, i, raw=T), data=df)
cv.err[i] = cv.glm(df, glm.fit, K=n.obs)$delta[1]
}
cv.err
glm.fit = glm(y~x, data=df)
a = summary(glm.fit)
names(a)
a$coefficients
a$coefficients[, 2]
sig = rep(NA, 5)
for (i in 1:5){
glm.fit = glm(y~x, data=df)
print( summary(glm.fit)$coefficients[-1, 4] )
}
# (f)
sig = rep(NA, 5)
for (i in 1:5){
glm.fit = glm(y~poly(x, i, raw=T), data=df)
print( summary(glm.fit)$coefficients[-1, 4] )
}
sig = rep(NA, 5)
for (i in 1:5){
glm.fit = glm(y~poly(x, i, raw=T), data=df)
print( summary(glm.fit)$coefficients[-1, 4] )
print('\n')
}
sig = rep(NA, 5)
for (i in 1:5){
glm.fit = glm(y~poly(x, i, raw=T), data=df)
print( summary(glm.fit)$coefficients[-1, 4] )
print('/n')
}
# (f)
sig = rep(NA, 5)
for (i in 1:5){
glm.fit = glm(y~poly(x, i, raw=T), data=df)
print( paste0('degree = ', i) )
print( summary(glm.fit)$coefficients[-1, 4] )
}
library(MASS)
attach(Boston)
?Boston
mean(medv)
sigma = sd(medv)/length(medv)
mu = mean(medv)
sigma
sigma = sd(medv)/sqrt( length(medv) )
sigma
library(boot)
boot.fn = function(data, index){
return( mean( data$medv[index] ) )
}
boot(Boston, boot.fn, R=1000)
qnorm(0.95)
qnorm(0.975)
a = boot(Boston, boot.fn, R=1000)
names(a)
a$statistic()
a$statistic
a
names(a)
a$t
a$R
a$weights
a$strata
a$stype
a$t0
a$call
summary(a)
summary(a)$bootSE
summary(a)
summary(a)$bootSE
sd(a$t)
a
set.seed(1)
boot.result = boot(Boston, boot.fn, R=1000)
boot.result
low = mu - qnorm(0.975) * sd(boot.result$t)
up = mu + qnorm(0.975) * sd(boot.result$t)
low
up
t.test(Boston$medv)
med = median(medv)
boot.fn = function(data, index){
return( median(data$medv[index]) )
}
set.seed(1)
boot.result = boot(Boston, boot.fn, R=1000)
boot.result
q.10 = quantile(medv), 0.1
q.10 = quantile(medv, 0.1)
q.10
boot.fn = function(data, index){
return( quantile(data$medv[index], 0.1) )
}
set.seed(1)
boot.result = boot(Boston, boot.fn, R=1000)
boot.result
library(ISLR)
attach(Hitters)
names(Hitters)
dim(Hitters)
sum( is.na(Hitters$Salary) )
Hitters = na.omit(Hitters)
dim(Hitters)
sum( is.na( Hitters$Salary ) )
library(leaps)
install.packages('leaps')
library(leaps)
regfit.full = regsubsets(Salary~., Hitters)
summary(regfit.full)
summary(regfit.full)
regfit.full = regsubsets(Salary~., Hitters, nvmax=19)
reg.summary = summary(regfit.full)
names(reg.summary)
reg.summary$rsq
par(mfrow=c(2,2))
plot(reg.summary$rss, xlab='Number of Variables', ylab='RSS', type='l')
plot(reg.summary$rsq, xlab='Number of Variables', ylab='R2', type='l')
plot(reg.summary$cp, xlab='Number of Variables', ylab='Cp', type='l')
plot(reg.summary$bic, xlab='Number of Variables', ylab='BIC', type='l')
par(mfrow=c(2,2))
plot(reg.summary$rss, xlab='Number of Variables', ylab='RSS', type='l')
idx = which.max(reg.summary$rss)
points(idx, reg.summary$rss[idx], col='red', cex=2, pch=20)
plot(reg.summary$rsq, xlab='Number of Variables', ylab='R2', type='l')
idx = which.max(reg.summary$rsq)
points(idx, reg.summary$rsq[idx], col='red', cex=2, pch=20)
plot(reg.summary$cp, xlab='Number of Variables', ylab='Cp', type='l')
idx = which.max(reg.summary$cp)
points(idx, reg.summary$cp[idx], col='red', cex=2, pch=20)
plot(reg.summary$bic, xlab='Number of Variables', ylab='BIC', type='l')
idx = which.max(reg.summary$bic)
points(idx, reg.summary$bic[idx], col='red', cex=2, pch=20)
par(mfrow=c(2,2))
plot(reg.summary$rss, xlab='Number of Variables', ylab='RSS', type='l')
idx = which.min(reg.summary$rss)
points(idx, reg.summary$rss[idx], col='red', cex=2, pch=20)
plot(reg.summary$rsq, xlab='Number of Variables', ylab='R2', type='l')
idx = which.max(reg.summary$rsq)
points(idx, reg.summary$rsq[idx], col='red', cex=2, pch=20)
plot(reg.summary$cp, xlab='Number of Variables', ylab='Cp', type='l')
idx = which.min(reg.summary$cp)
points(idx, reg.summary$cp[idx], col='red', cex=2, pch=20)
plot(reg.summary$bic, xlab='Number of Variables', ylab='BIC', type='l')
idx = which.min(reg.summary$bic)
points(idx, reg.summary$bic[idx], col='red', cex=2, pch=20)
names(reg.summary)
names(regfit.full)
par(mfrow=c(2,2))
plot(regfit.full, scale='r2')
plot(regfit.full, scale='adjr2')
plot(regfit.full, scale='Cp')
plot(regfit.full, scale='bic')
coeff(regfit.full, 6)
coef(regfit.full, 6)
regfit.fwd = regsubsets(Salary~., Hitters, nvmax=19, method='forward')
summary(regfit.fwd)
regfit.bwd = regsubsets(Salary~., Hitters, nvmax=19, method='backward')
summary(regfit.bwd)
plot(regfit.fwd, scale='bic')
par(mfrow=c(1,1))
plot(regfit.fwd, scale='bic')
plot(regfit.fwd)
plot(regfit.fwd)
coef(regfit.full, 7)
coef(regfit.fwd, 7)
coef(regfit.bwd, 7)
dim
# *************** 6.5.3 ***************
set.seed(1)
dim(Hitters)
set.seed(1)
n.obs = nrow(Hitters)
train = sample(n.obs, round(n.obs/2), replace=F)
regfit.best = regsubsets(Salary~., data=Hitters[train, ], nvmax=19)
test.mat = model.matrix(Salary~., data=Hitters[-train, ])
test.mat
View(test.mat)
View(test.mat)
typeof(test.mat)
class(test.mat)
val.err = rep(NA, 19)
for (i in 1:19){
coeff = coef(regfit.best, i)
pred = test.mat[, names(coeff)] %*% coeff
val.err[i] = mean( (Hitters$Salary[-train] - pred)^2 )
}
val.err
plot(val.err, xlab='Number of Variables', ylab='Test Error', type='l')
idx = which.min(val.err)
points(idx, val.err[idx], col='red', cex=2, pch=20)
idx
coef(regfit.best, idx)
summary(regfit.best)
regfit.best[[2]]
idx
regfit.best = regsubsets(Salary~., Hitters, nvmax=idx)
coef(regfit.best, idx)
set.seed(1)
n.obs = nrow(Hitters)
train = sample(n.obs, round(n.obs/2), replace=F)
regfit.best = regsubsets(Salary~., data=Hitters[train, ], nvmax=19)
test.mat = model.matrix(Salary~., data=Hitters[-train, ])
val.err = rep(NA, 19)
for (i in 1:19){
coeff = coef(regfit.best, i)
pred = test.mat[, names(coeff)] %*% coeff
val.err[i] = mean( (Hitters$Salary[-train] - pred)^2 )
}
plot(val.err, xlab='Number of Variables', ylab='Test Error', type='l')
idx = which.min(val.err)
points(idx, val.err[idx], col='red', cex=2, pch=20)
coef(regfit.best, idx)
predict <- function(object, newdata, id){
form = as.formula(object$call[[2]])
mat = model.matrix(form, newdata)
coeff = coef(object, id)
return( mat[, names(coeff)] %*% coeff )
}
regfit.best = regsubsets(Salary~., Hitters, nvmax=idx)
coef(regfit.best, idx)
set.seed(1)
k = 10
train = sample(1:k, n.obs, replace=T)
cv.err = matrix(NA, k, 19, dimnames=list(NULL, paste(1:19)))
View(cv.err)
View(cv.err)
regfit.best$call
regfit.best$call[[2]]
regfit.best$call[[1]]
train
set.seed(1)
k = 10
train = sample(1:k, n.obs, replace=T)
cv.err = matrix(NA, k, 19, dimnames=list(NULL, paste(1:19)))
for (i in 1:k){
best.fit = regsubsets(Salary~., Hitters[train!=i, ], nvmax=19)
for (j in 1:19){
pred = predict(best.fit, Hitters[train==i], j)
cv.err[i, j] = mean( (Hitters$Salary[train==i] - pred)^2 )
}
}
set.seed(1)
k = 10
train = sample(1:k, n.obs, replace=T)
cv.err = matrix(NA, k, 19, dimnames=list(NULL, paste(1:19)))
for (i in 1:k){
best.fit = regsubsets(Salary~., Hitters[train!=i, ], nvmax=19)
for (j in 1:19){
pred = predict(best.fit, Hitters[train==i, ], j)
cv.err[i, j] = mean( (Hitters$Salary[train==i] - pred)^2 )
}
}
cv.err
set.seed(1)
k = 10
folds = sample(1:k, n.obs, replace=T)
cv.err = matrix(NA, k, 19, dimnames=list(NULL, paste(1:19)))
for (i in 1:k){
best.fit = regsubsets(Salary~., Hitters[folds!=i, ], nvmax=19)
for (j in 1:19){
pred = predict(best.fit, Hitters[folds==i, ], j)
cv.err[i, j] = mean( (Hitters$Salary[folds==i] - pred)^2 )
}
}
dim(cv.err)
class(cv.err)
colMeans(cv.err)
cv.err
mean.cv.err = colMeans(cv.err)
mean.cv.err
plot(mean.cv.err, xlab='Number of Variables', type='b')
idx = which.min(mean.cv.err)
points(idx, mean.cv.err[idx], col='red', cex=2, pch=20)
reg.best = regsubsets(Salary~., Hitters, nvmax=idx)
coef(reg.best, idx)
# *************** 6.6 ***************
library(glmnet)
install.packages("glmnet")
# *************** 6.6 ***************
library(glmnet)
attach(Hitters)
library(ISLR)
source('C:/Users/Penghao Chen/Desktop/R/ISLR/RLab/Ch6_2.R', echo=TRUE)
grid = 10^seq(10, -2, length=100)
ridge.mod = glmnet(x, y, alpha=0, lambda=grid)
dim( coef(ridge.mod) )
grid
ridge.mod$lambda[50]
coef( ridge.mod )[, 50]
sqrt( sum(coef(ridge.mod)[-1, 50]^2) )
ridge.mod$lambda[60]
coef(ridge.mod)[60]
coef(ridge.mod)[,60]
sqrt( sum(coef(ridge.mod)[,60]^2) )
sqrt( sum(coef(ridge.mod)[-1,60]^2) )
predict(ridge.mod, s=50, type='coefficients')[1:20, ]
predict(ridge.mod, s=50, type='coefficients')
2//2
sample(1:10, 2.5)
set.seed(1)
train = sample(1:nrow(x), nrow(x)/2)
test = (-train)
y.test = y[test]
ridge.mod = glmnet(x[train, ], y[train, ], alpha=0, lambda=grid, thresh=1e-12)
ridge.pred = predict(ridge.mod, s=4, newx=x[test, ])
mean( (ridge.pred-y.test)^2 )
ridge.mod = glmnet(x[train, ], y[train, ], alpha=0, lambda=grid, thresh=1e-12)
# *************** 6.6 ***************
library(glmnet)
library(ISLR)
attach(Hitters)
Hitters = na.omit(Hitters)
x = model.matrix(Salary~., data=Hitters)[, -1]
y = Hitters$Salary
# *************** 6.6.1 ***************
grid = 10^seq(10, -2, length=100)
ridge.mod = glmnet(x, y, alpha=0, lambda=grid)
dim( coef(ridge.mod) )
ridge.mod$lambda[50]
coef( ridge.mod )[, 50]
sqrt( sum(coef(ridge.mod)[-1, 50]^2) )    # L2 norm
ridge.mod$lambda[60]
coef(ridge.mod)[,60]
sqrt( sum(coef(ridge.mod)[-1,60]^2) )
predict(ridge.mod, s=50, type='coefficients')
set.seed(1)
train = sample(1:nrow(x), nrow(x)/2)
test = (-train)
y.test = y[test]
ridge.mod = glmnet(x[train, ], y[train, ], alpha=0, lambda=grid, thresh=1e-12)
ridge.mod = glmnet(x[train, ], y[train], alpha=0, lambda=grid, thresh=1e-12)
ridge.pred = predict(ridge.mod, s=4, newx=x[test, ])
mean( (ridge.pred-y.test)^2 )
mean( (mean(y[train]) - y.test)^2 )
ridge.pred = predict( ridge.mod, s=1e10, newx=x[test, ])
mean( (ridge.pred - y.test)^2 )
ridge.pred = predict( ridge.mod, s=0, newx=x[test, ], exact=T)
# *************** 6.6 ***************
library(glmnet)
library(ISLR)
attach(Hitters)
Hitters = na.omit(Hitters)
x = model.matrix(Salary~., data=Hitters)[, -1]
y = Hitters$Salary
# *************** 6.6.1 ***************
grid = 10^seq(10, -2, length=100)
ridge.mod = glmnet(x, y, alpha=0, lambda=grid)
dim( coef(ridge.mod) )
ridge.mod$lambda[50]
coef( ridge.mod )[, 50]
sqrt( sum(coef(ridge.mod)[-1, 50]^2) )    # L2 norm
ridge.mod$lambda[60]
coef(ridge.mod)[,60]
sqrt( sum(coef(ridge.mod)[-1,60]^2) )
predict(ridge.mod, s=50, type='coefficients')
set.seed(1)
train = sample(1:nrow(x), nrow(x)/2)
test = (-train)
y.test = y[test]
ridge.mod = glmnet(x[train, ], y[train], alpha=0, lambda=grid, thresh=1e-12)
ridge.pred = predict(ridge.mod, s=4, newx=x[test, ])
mean( (ridge.pred-y.test)^2 )
mean( (mean(y[train]) - y.test)^2 )
ridge.pred = predict( ridge.mod, s=1e10, newx=x[test, ])
mean( (ridge.pred - y.test)^2 )
ridge.pred = predict( ridge.mod, s=0, newx=x[test, ], exact=T)
mean( (ridge.pred - y.test)^2 )
ridge.pred = predict( ridge.mod, s=0, newx=x[test, ], exact=T)
ridge.mod = glmnet(x[train, ], y[train], alpha=0, lambda=grid, thresh=1e-12)
ridge.pred = predict( ridge.mod, s=0, newx=x[test, ], exact=T)
ridge.pred=predict (ridge .mod ,s=0, newx=x[test ,], exact=T)
ridge.pred = predict(ridge .mod ,s=0, newx=x[test ,], exact=T)
ridge.pred = predict(ridge.mod, s=0, newx=x[test, ], exact=T)
ridge.mod = glmnet(x, y, alpha=0, lambda=grid, thresh=1e-12)
ridge.pred = predict(ridge.mod, s=0, newx=x[test, ], exact=T)
ridge.mod = glmnet(x[train, ], y[train],
ridge.mod = glmnet(x[train, ], y[train], alpha=0, lambda=grid, thresh=1e-12)
)
ridge.mod = glmnet(x[train, ], y[train], alpha=0, lambda=grid, thresh=1e-12)
ridge.pred = predict(ridge.mod, s=0, newx=x[test, ], exact=T, type='response')
ridge.pred = predict(ridge.mod, s=0, newx=x[test, ], exact=T, type='coefficients')
x
class(x)
# ridge.pred = predict( ridge.mod, s=0, newx=x[test, ], exact=T)
# mean( (ridge.pred - y.test)^2 )
lm.fit = lm(y~x, subset=train)
predict(ridge.mod, s=0, exact=T, type='coefficients')[1:20, ]
ridge.pred = predict( ridge.mod, s=0, x=x[train, ], y=y[train], newx=x[test, ], exact=T)
mean( (ridge.pred - y.test)^2 )
lm.fit = lm(y~x, subset=train)
predict(ridge.mod, s=0, exact=T, type='coefficients')[1:20, ]
predict(ridge.mod, s=0, x=x[train, ], y=y[train], exact=T, type='coefficients')[1:20, ]
source('C:/Users/Penghao Chen/Desktop/R/ISLR/RLab/Ch6_2.R', echo=TRUE)
set.seed(1)
cv.out = cv.glmnet(x[train, ], y[train], alpha=0)
plot(cv.out)
bestlam = cv.out$lambda.min
bestlam
ridge.pred = pred(ridge.mod, s=bestlam, newx=x[test, ])
ridge.pred = predict(ridge.mod, s=bestlam, newx=x[test, ])
mean( (ridge.pred - y.test)^2 )
predict(ridge.mod, s=bestlam, x=x, y=y)
predict(ridge.mod, s=bestlam, x=x, y=y, type='coefficients')
ridge.mod = glmnet(x, y, alpha=0)
predict(ridge.mod, s=bestlam, x=x, y=y, type='coefficients')
predict(ridge.mod, s=bestlam, type='coefficients')
# *************** 6.6.2 ***************
lasso.mod = glmnet(x[train, ], y[train], alpha=1, lambda=grid)
plot(lasso.mod)
plot(cv.out)
plot(lasso.mod)
cv.out = cv.glmnet(x[train, ], y[train], alpha=1)
set.seed(1)
cv.out = cv.glmnet(x[train, ], y[train], alpha=1)
plot(cv.out)
bestlam = cv.out$lambda.min
bestlam
lasso.pred = predict(lasso.mod, s=bestlam, newx=x[train, ])
mean( (lasso.pred - y.test)^2 )
lasso.pred = predict(lasso.mod, s=bestlam, newx=x[test, ])
mean( (lasso.pred - y.test)^2 )
lasso.mod = glmnet(x, y, alpha=1)
predict(lasso.mod, s=bestlam)
lasso.coef = predict(lasso.mod, s=bestlam, type='coefficients')
lasso.coef
