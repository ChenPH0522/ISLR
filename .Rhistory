coefi = coefficients(bs.model, id=8)
# test error
x_cols = names(coefi)[-1]
X.test = Boston[test, x_cols]
Y.test = Boston$crim[test]
Y.pred = coefi[1] + data.matrix(X.test) %*% coefi[-1]
bs.test.mse = mean( (Y.pred - Y.test)^2 )    # 39.56733
# forward selection
fs.model = regsubsets(crim~., data=Boston, subset=train, nvmax=14, method='forward')
fs.summary = summary(fs.model)
which.min(fs.summary$cp)
which.min(fs.summary$bic)
which.max(fs.summary$adjr2)
# same situation, use 8
coefi = coefficients(fs.model, id=8)
coefi
X.test = Boston[test, x_cols]
Y.pred = coefi[1] + data.matrix(X.test) %*% coefi
Y.pred = coefi[1] + data.matrix(X.test) %*% coefi[-1]
fs.test.mse = mean( (Y.test - Y.pred)^2 )
fs.test.mse
library(MASS)
attach(Boston)
Boston = na.omit(Boston)
# (a)
set.seed(1)
train = sample(nrow(Boston), nrow(Boston)/2)
test = -(train)
# best subset
library(leaps)
fs.model = regsubsets(crim~., data=Boston, subset=train, nvmax=14, method='forward')
fs.summary = summary(fs.model)
which.min(fs.summary$cp)
which.min(fs.summary$bic)
which.max(fs.summary$adjr2)
# same situation, use 8
coefi = coefficients(fs.model, id=8)
# (Intercept)           zn          nox           rm          dis          rad      ptratio
# 13.49137141   0.04686838 -17.03403009   1.57135072  -1.29059959   0.55947948  -0.41356877
# lstat         medv
# 0.17036943  -0.26409286
x_cols = names(coefi)[-1]
X.test = Boston[test, x_cols]
Y.test = Boston$crim[test]
Y.pred = coefi[1] + data.matrix(X.test) %*% coefi[-1]
fs.test.mse = mean( (Y.test - Y.pred)^2 )      # 39.56733
# backward selection
bks.model = regsubsets(crim~., data=Boston, subset=train, method='backward')
bks.summary = summary(bks.model)
which.min(bks.summary$cp)
which.min(bks.summary$bic)
which.min(bks.summary$adjr2)
which.max(bks.summary$adjr2)
# the same, use 8
coefi = coefficients(bks.model, id=8)
coefi
x_cols = names(coefi)
x_cols = names(coefi)[-1]
Y.pred = coefi[1] + data.matrix(X.test) %*% coefi[-1]
bks.test.mse = mean( (Y.pred - Y.test)^2 )
bks.test.mse
# II.1 Lasso
library(glmnet)
?glmnet
X.train = Boston[train, -1]
Y.train = Boston$crim[train]
lasso.model = glmnet(data.matrix(X.train), Y.train, alpha=1)
summary(lasso.model)
cv.lasso = cv.glmnet(data.matrix(X.train), Y.train, alpha=1)
best.lambda = cv.lasso$lambda.min
best.lambda
X.test = Boston[test, -1]
Y.test = Boston$crim[test]
lasso.pred = predict(cv.lasso, s=best.lambda, newx=data.matrix(X.test), type='response')
lasso.mse = mean( (Y.pred - lasso.pred)^2 )
lasso.mse
lasso.model = predict(cv.lasso, s=best.lambda, newx=data.matrix(X.test), type='cofficients')
lasso.model = predict(cv.lasso, s=best.lambda, newx=data.matrix(X.test), type='cofficient')
lasso.model = predict(cv.lasso, s=best.lambda, newx=data.matrix(X.test), type='coefficients')
lasso.model
predict(bks.model, id=3)
predict(bks.model, Boston[1:100, ], id=3)
lasso.pred
lasso.mse = mean( (Y.test - lasso.pred)^2 )     # 0.3674139
lasso.mse
# II.2 Ridge
cv.ridge = glmnet(data.matrix(X.train), Y.train, alpha=0)
# II.2 Ridge
cv.ridge = cv.glmnet(data.matrix(X.train), Y.train, alpha=0)
best.lambda = cv.ridge$lambda.min
best.lambda
ridge.pred = predict(cv.ridge, newx=data.matrix(X.test), s=best.lambda, type='response')
ridge.mse = mean( (Y.test - ridge.pred)^2 )
ridge.mse
ridge.model = predict(cv.ridge, newx=data.matrix(X.test), s=best.lambda, type='coefficients')
ridge.model
# III. PCR
library(pls)
?pcr
pls.model = pcr(crim~., data=Boston, subset=train, scale=T, validation='CV')
validationplot(pls.model)
pls.model$ncomp
summary(pls.model)
summary(pls.model)
pls.pred = predict(pls.model, newdata=Boston[test, -1], ncomp=4)
pls.pred = predict(pls.model, newdata=Boston[test, -1], ncomp=4, type='response')
pcr.model = pcr(crim~., data=Boston, subset=train, scale=T, validation='CV')
validationplot(pls.model)
summary(pls.model)     # choose ncomp=4
pcr.pred = predict(pls.model, newdata=Boston[test, -1], ncomp=4, type='response')
pcr.mse = mean( (Y.test - pcr.pred)^2 )
pcr.mse
pcr.pred = predict(pls.model, newdata=Boston[test, -1], ncomp=10, type='response')
pcr.mse = mean( (Y.test - pcr.pred)^2 )    # 40.46918
pcr.mse
pcr.pred = predict(pls.model, newdata=Boston[test, -1], ncomp=13, type='response')
pcr.mse = mean( (Y.test - pcr.pred)^2 )    # 40.46918
pcr.mse
# Re-fit the model on the full dataset:
best.lambda = cv.lasso$lambda.min
lasso.fit = glmnet(data.matrix(Boston[, -1]), Boston$crim, alpha=1)
lasso.fit
lasso.model = predict(lasso.fit, type='response')
lasso.fit = glmnet(data.matrix(Boston[, -1]), Boston$crim, alpha=1)
summary(lasso.fit)
?glmnet
lasso.fit = glmnet(data.matrix(Boston[, -1]), lambda=best.lambda, Boston$crim, alpha=1)
lasso.fit
summary(lasso.fit)
coefficients(lasso.fit)
coefi = coefficients(lasso.fit)
coefi
library(parallel)
detectCores()
library(ISLR)
attach(Wage)
# ---------------- 7.8.1 ----------------
fit = lm(wage~poly(age, 4), data=Wage)
coef(fit)
coef( summar(fit) )
coef( summary(fit) )
fit2 = lm(wage~poly(age, 4, raw=TRUE), data=Wage)
coef( summary(fit2) )
fit2a = lm(wage~age+I(age, 2)+I(age, 3)+I(age, 4), data=Wage)
coef(fit2a)
fit2a = lm(wage~age+I(age^2)+I(age^3)+I(age^4), data=Wage)
coef(fit2a)
?I()
age^2
class(age^2)
class(I(age^2))
fit2b = lm(wage~cbind(age, age^2, age^3, age^4), data=Wage)
coef(fit2b)
agelims = range(age)
age.grid = seq(agelims[1], agelims[2])
preds = predict(fit, newdata=list(age=age.grid), se=TRUE)
se.bands  = cbind(preds$fit - 2*preds$se.fit, preds$fit + 2*preds$se.fit)
se.bands = cbind(preds$fit + 2*preds$se.fit, preds$fit - 2*preds$se.fit)
par(mfrow=c(1, 2), mar=c(4.5, 4.5, 1, 1), oma=c(0, 0, 1, 0))
plot(age, wage, xlim=agelims, cex=0.5, col='darkgrey')
title('Degree-4 Polynomial', outer=TRUE)
lines(age.grid, preds$fit, lwd=2, col='blue')
matlines(age.grid, se.bands, lwd=1, lty=3, col='blue')
coef(summary(fit))
coef(summary(fit2))
a = coef(summary(fit2))
View(a)
View(a)
colnames(a)
class(a)
a[, 2]
a
colnames(a)
a["Std. Error"]
a[, "Std. Error"]
std = a[, "Std. Error"]
std
age.grid
x2 = c(1, 18, 18^2, 18^3, 18^4)
sum(x2 * (std^2))
preds$se.fit[1]
library(ISLR)
attach(Wage)
# ---------------- 7.8.1 ----------------
fit = lm(wage~poly(age, 4), data=Wage)
coef( summary(fit) )
fit2 = lm(wage~poly(age, 4, raw=TRUE), data=Wage)
coef( summary(fit2) )
fit2a = lm(wage~age+I(age^2)+I(age^3)+I(age^4), data=Wage)
coef(fit2a)
fit2b = lm(wage~cbind(age, age^2, age^3, age^4), data=Wage)
coef(fit2b)
agelims = range(age)
age.grid = seq(agelims[1], agelims[2])
preds = predict(fit, newdata=list(age=age.grid), se=TRUE)
se.bands = cbind(preds$fit + 2*preds$se.fit, preds$fit - 2*preds$se.fit)
par(mfrow=c(1, 2), mar=c(4.5, 4.5, 1, 1), oma=c(0, 0, 1, 0))
plot(age, wage, xlim=agelims, cex=0.5, col='darkgrey')
title('Degree-4 Polynomial', outer=TRUE)
lines(age.grid, preds$fit, lwd=2, col='blue')
matlines(age.grid, se.bands, lwd=1, lty=3, col='blue')
preds$fit[1:20]
preds2 = predict(fit2, newdata=list(age=age.grid), se=TRUE)
max(abs(preds$fit - preds$fit2))
preds2 = predict(fit2, newdata=list(age=age.grid), se=TRUE)
max(abs(preds$fit - preds2$fit))
fit.1 = lm(wage~age, data=Wage)
fit.2 = lm(wage~poly(age, 2), data=Wage)
fit.3 = lm(wage~poly(age, 3), data=wage)
fit.4 = lm(wage~poly(age, 4), data=Wage)
fit.5 = lm(wage~poly(age, 5), data=Wage)
anova(fit.1, fit.2, fit.3, fit.4, fit.5)
fit.1 = lm(wage~age, data=Wage)
fit.2 = lm(wage~poly(age, 2), data=Wage)
fit.3 = lm(wage~poly(age, 3), data=Wage)
fit.4 = lm(wage~poly(age, 4), data=Wage)
fit.5 = lm(wage~poly(age, 5), data=Wage)
anova(fit.1, fit.2, fit.3, fit.4, fit.5)
coef(summary(fit.5))
anova(fit.1, fit.2, fit.3)
fit.1 = lm(wage~education+age, data=Wage)
fit.2 = lm(wage~education+poly(age, 2), data=Wage)
fit.3 = lm(wage~education+poly(age, 3), data=Wage)
anova(fit.1, fit.2, fit.3)
fit = glm(I(wage>250)~poly(age, 4), data=Wage, family='binomial')
preds = predict(fit, newdata=list(age=age.grid), se=TRUE)
exp(0)
logit.iv  <- function(x){ return( exp(x) / (1 + exp(x)) ) }
pfit = logit.iv(preds$fit)
se.bands.logit = cbind(preds$fit + 2*preds$se.fit, preds$fit -  2*preds$se.fit)
se.bands.pfit = logit.iv(se.bands.logit)
preds = predict(fit, newdata=list(age=age.grid), se=TRUE, type='response')
preds = predict(fit, newdata=list(age=age.grid), se=TRUE, type='response')
plot(age, I(wage>250), xlim=agelims, type='n', ylim=c(0, 2))
points(jitter(age), I( (wage>250)/5 ), cex=0.5, pch='l', col='darkgrey')
lines(age.grid, preds$fit, lwd=2, col='blue')
matlines(age.grid, se.bands.pfit, lwd=1, col='blue', lty=3)
library(ISLR)
attach(Wage)
# ---------------- 7.8.1 ----------------
fit = lm(wage~poly(age, 4), data=Wage)
coef( summary(fit) )
fit2 = lm(wage~poly(age, 4, raw=TRUE), data=Wage)
coef( summary(fit2) )
fit2a = lm(wage~age+I(age^2)+I(age^3)+I(age^4), data=Wage)
coef(fit2a)
fit2b = lm(wage~cbind(age, age^2, age^3, age^4), data=Wage)
coef(fit2b)
agelims = range(age)
age.grid = seq(agelims[1], agelims[2])
preds = predict(fit, newdata=list(age=age.grid), se=TRUE)
se.bands = cbind(preds$fit + 2*preds$se.fit, preds$fit - 2*preds$se.fit)
par(mfrow=c(1, 2), mar=c(4.5, 4.5, 1, 1), oma=c(0, 0, 1, 0))
plot(age, wage, xlim=agelims, cex=0.5, col='darkgrey')
title('Degree-4 Polynomial', outer=TRUE)
lines(age.grid, preds$fit, lwd=2, col='blue')
matlines(age.grid, se.bands, lwd=1, lty=3, col='blue')
preds2 = predict(fit2, newdata=list(age=age.grid), se=TRUE)
max(abs(preds$fit - preds2$fit))
fit.1 = lm(wage~age, data=Wage)
fit.2 = lm(wage~poly(age, 2), data=Wage)
fit.3 = lm(wage~poly(age, 3), data=Wage)
fit.4 = lm(wage~poly(age, 4), data=Wage)
fit.5 = lm(wage~poly(age, 5), data=Wage)
anova(fit.1, fit.2, fit.3, fit.4, fit.5)
coef(summary(fit.5))
fit.1 = lm(wage~education+age, data=Wage)
fit.2 = lm(wage~education+poly(age, 2), data=Wage)
fit.3 = lm(wage~education+poly(age, 3), data=Wage)
anova(fit.1, fit.2, fit.3)
fit = glm(I(wage>250)~poly(age, 4), data=Wage, family='binomial')
preds = predict(fit, newdata=list(age=age.grid), se=TRUE)
logit.iv  <- function(x){ return( exp(x) / (1 + exp(x)) ) }
pfit = logit.iv(preds$fit)
se.bands.logit = cbind(preds$fit + 2*preds$se.fit, preds$fit -  2*preds$se.fit)
se.bands.pfit = logit.iv(se.bands.logit)
preds = predict(fit, newdata=list(age=age.grid), se=TRUE, type='response')
plot(age, I(wage>250), xlim=agelims, type='n', ylim=c(0, 0.2))
points(jitter(age), I( (wage>250)/5 ), cex=0.5, pch='l', col='darkgrey')
lines(age.grid, preds$fit, lwd=2, col='blue')
matlines(age.grid, se.bands.pfit, lwd=1, col='blue', lty=3)
cut(age, 4)
table(cut(age, 4))
fit = lm(wage~cut(age, 4), data=Wage)
coef(summary(fit))
library(ISLR)
attach(Wage)
# ---------------- 7.8.2 ----------------
library(splines)
bs(age, knots=c(25, 40, 60))
bs(age, knots=c(25, 40, 60))
bs(age, knots=c(25, 40, 60))
library(ISLR)
attach(Wage)
# ---------------- 7.8.1 ----------------
fit = lm(wage~poly(age, 4), data=Wage)
coef( summary(fit) )
fit2 = lm(wage~poly(age, 4, raw=TRUE), data=Wage)
coef( summary(fit2) )
fit2a = lm(wage~age+I(age^2)+I(age^3)+I(age^4), data=Wage)
coef(fit2a)
fit2b = lm(wage~cbind(age, age^2, age^3, age^4), data=Wage)
coef(fit2b)
agelims = range(age)
age.grid = seq(agelims[1], agelims[2])
preds = predict(fit, newdata=list(age=age.grid), se=TRUE)
se.bands = cbind(preds$fit + 2*preds$se.fit, preds$fit - 2*preds$se.fit)
par(mfrow=c(1, 2), mar=c(4.5, 4.5, 1, 1), oma=c(0, 0, 1, 0))
plot(age, wage, xlim=agelims, cex=0.5, col='darkgrey')
title('Degree-4 Polynomial', outer=TRUE)
lines(age.grid, preds$fit, lwd=2, col='blue')
matlines(age.grid, se.bands, lwd=1, lty=3, col='blue')
preds2 = predict(fit2, newdata=list(age=age.grid), se=TRUE)
max(abs(preds$fit - preds2$fit))
fit.1 = lm(wage~age, data=Wage)
fit.2 = lm(wage~poly(age, 2), data=Wage)
fit.3 = lm(wage~poly(age, 3), data=Wage)
fit.4 = lm(wage~poly(age, 4), data=Wage)
fit.5 = lm(wage~poly(age, 5), data=Wage)
anova(fit.1, fit.2, fit.3, fit.4, fit.5)
coef(summary(fit.5))
fit.1 = lm(wage~education+age, data=Wage)
fit.2 = lm(wage~education+poly(age, 2), data=Wage)
fit.3 = lm(wage~education+poly(age, 3), data=Wage)
anova(fit.1, fit.2, fit.3)
fit = glm(I(wage>250)~poly(age, 4), data=Wage, family='binomial')
preds = predict(fit, newdata=list(age=age.grid), se=TRUE)
logit.iv  <- function(x){ return( exp(x) / (1 + exp(x)) ) }
pfit = logit.iv(preds$fit)
se.bands.logit = cbind(preds$fit + 2*preds$se.fit, preds$fit -  2*preds$se.fit)
se.bands.pfit = logit.iv(se.bands.logit)
preds = predict(fit, newdata=list(age=age.grid), se=TRUE, type='response')
plot(age, I(wage>250), xlim=agelims, type='n', ylim=c(0, 0.2))
points(jitter(age), I( (wage>250)/5 ), cex=0.5, pch='l', col='darkgrey')
lines(age.grid, preds$fit, lwd=2, col='blue')
matlines(age.grid, se.bands.pfit, lwd=1, col='blue', lty=3)
table(cut(age, 4))
fit = lm(wage~cut(age, 4), data=Wage)
coef(summary(fit))
fit = lm(wage~bs(age, knots=c(25, 40, 60)), data=Wage)
preds = predict(fit, newdata=list(age=age.grid), se=TRUE)
pred = predict(fit, newdata=list(age=age.grid), se=TRUE)
plot(age, wage, col='gray')
lines(age.grid, pred$fit, lwd=2)
lines(age.grid, pred$fit-2*pred$se.fit, lty='dashed')
lines(age.grid, pred$fit+2*pred$se.fit, lty='dashed')
dim(bs(age, knots=c(25, 40, 60)))
dim(bs(age, df=6))
attr(bs(age, df=6), 'knots')
fit2 = lm(wage~ns(age, df=4), data=Wage)
pred2 = predict(fit2, newdata=list(age=age.grid), se=TRUE)
ns(age, df=4)
fit = smooth.spline(age, wage, df=16)
fit2 = smooth.spline(age, wage, cv=TRUE)
fit2$df
class(fit.2)
class(fit2)
plot(age, wage, xlim=agelims, cex=0.5, col='darkgrey')
title('Smoothing Spline')
lines(fit, col='red', lwd=2)
lines(fit2, col='blue', lwd=2)
legend('topright', legend=c('16 DF', paste(round(fit2$df, 2), 'DF')), col=c('red', 'blue'), lty=1, lwd=2, cex=0.8)
plot(age, wage, xlim=agelims, cex=0.5, col='darkgrey')
title('Smoothing Spline')
lines(fit, col='red', lwd=2)
lines(fit2, col='blue', lwd=2)
legend('topright', legend=c('16 DF', paste(round(fit2$df, 1), 'DF')), col=c('red', 'blue'), lty=1, lwd=2, cex=0.8)
fit = loess(wage~age, span=0.2, data=Wage)
fit2 = loess(wage~age, span=0.5, data=Wage)
pred = predict(fit, newdata=list(age=age.grid), se=TRUE)
pred2 = predict(fit2, newdata=list(age=age.grid), se=TRUE)
pred = predict(fit, data.frame(age.grid), se=TRUE)
pred2 = predict(fit2, data.frame(age=age.grid), se=TRUE)
fit = loess(wage~age, span=0.2, data=Wage)
fit2 = loess(wage~age, span=0.5, data=Wage)
pred = predict(fit, data.frame(age.grid), se=TRUE)
pred2 = predict(fit2, data.frame(age=age.grid), se=TRUE)
fit = loess(wage~age, span=0.2, data=Wage)
fit2 = loess(wage~age, span=0.5, data=Wage)
pred = predict(fit, data.frame(age=age.grid), se=TRUE)
pred2 = predict(fit2, data.frame(age=age.grid), se=TRUE)
plot(age, wage, xlim=agelims, cex=0.5, col='darkgrey')
title('Local Regression')
lines(age.grid, pred$fit, col='red', lwd=2)
lines(age.grid, pred2$fit, col='blue', lwd=2)
legend('topright', legend=c('Span = 0.2', 'Span = 0.5'), col=c('red', 'blue'), lty=1, lwd=2, cex=0.8)
# ---------------- 7.8.3 ----------------
gam1 = lm(wage~ns(year, 4)+ns(age, 5)+education, data=Wage)
library(ISLR)
attach(Wage)
# ---------------- 7.8.1 ----------------
fit = lm(wage~poly(age, 4), data=Wage)
coef( summary(fit) )
fit2 = lm(wage~poly(age, 4, raw=TRUE), data=Wage)
coef( summary(fit2) )
fit2a = lm(wage~age+I(age^2)+I(age^3)+I(age^4), data=Wage)
coef(fit2a)
fit2b = lm(wage~cbind(age, age^2, age^3, age^4), data=Wage)
coef(fit2b)
agelims = range(age)
age.grid = seq(agelims[1], agelims[2])
preds = predict(fit, newdata=list(age=age.grid), se=TRUE)
se.bands = cbind(preds$fit + 2*preds$se.fit, preds$fit - 2*preds$se.fit)
par(mfrow=c(1, 2), mar=c(4.5, 4.5, 1, 1), oma=c(0, 0, 1, 0))
plot(age, wage, xlim=agelims, cex=0.5, col='darkgrey')
title('Degree-4 Polynomial', outer=TRUE)
lines(age.grid, preds$fit, lwd=2, col='blue')
matlines(age.grid, se.bands, lwd=1, lty=3, col='blue')
preds2 = predict(fit2, newdata=list(age=age.grid), se=TRUE)
max(abs(preds$fit - preds2$fit))
fit.1 = lm(wage~age, data=Wage)
fit.2 = lm(wage~poly(age, 2), data=Wage)
fit.3 = lm(wage~poly(age, 3), data=Wage)
fit.4 = lm(wage~poly(age, 4), data=Wage)
fit.5 = lm(wage~poly(age, 5), data=Wage)
anova(fit.1, fit.2, fit.3, fit.4, fit.5)
coef(summary(fit.5))
fit.1 = lm(wage~education+age, data=Wage)
fit.2 = lm(wage~education+poly(age, 2), data=Wage)
fit.3 = lm(wage~education+poly(age, 3), data=Wage)
anova(fit.1, fit.2, fit.3)
fit = glm(I(wage>250)~poly(age, 4), data=Wage, family='binomial')
preds = predict(fit, newdata=list(age=age.grid), se=TRUE)
logit.iv  <- function(x){ return( exp(x) / (1 + exp(x)) ) }
pfit = logit.iv(preds$fit)
se.bands.logit = cbind(preds$fit + 2*preds$se.fit, preds$fit -  2*preds$se.fit)
se.bands.pfit = logit.iv(se.bands.logit)
preds = predict(fit, newdata=list(age=age.grid), se=TRUE, type='response')
plot(age, I(wage>250), xlim=agelims, type='n', ylim=c(0, 0.2))
points(jitter(age), I( (wage>250)/5 ), cex=0.5, pch='l', col='darkgrey')
lines(age.grid, preds$fit, lwd=2, col='blue')
matlines(age.grid, se.bands.pfit, lwd=1, col='blue', lty=3)
table(cut(age, 4))
fit = lm(wage~cut(age, 4), data=Wage)
coef(summary(fit))
# ---------------- 7.8.2 ----------------
library(splines)
fit = lm(wage~bs(age, knots=c(25, 40, 60)), data=Wage)
pred = predict(fit, newdata=list(age=age.grid), se=TRUE)
plot(age, wage, col='gray')
lines(age.grid, pred$fit, lwd=2)
lines(age.grid, pred$fit-2*pred$se.fit, lty='dashed')
lines(age.grid, pred$fit+2*pred$se.fit, lty='dashed')
dim(bs(age, knots=c(25, 40, 60)))
dim(bs(age, df=6))
attr(bs(age, df=6), 'knots')
fit2 = lm(wage~ns(age, df=4), data=Wage)
pred2 = predict(fit2, newdata=list(age=age.grid), se=TRUE)
fit = smooth.spline(age, wage, df=16)
fit2 = smooth.spline(age, wage, cv=TRUE)
fit2$df
plot(age, wage, xlim=agelims, cex=0.5, col='darkgrey')
title('Smoothing Spline')
lines(fit, col='red', lwd=2)
lines(fit2, col='blue', lwd=2)
legend('topright', legend=c('16 DF', paste(round(fit2$df, 1), 'DF')), col=c('red', 'blue'), lty=1, lwd=2, cex=0.8)
fit = loess(wage~age, span=0.2, data=Wage)
fit2 = loess(wage~age, span=0.5, data=Wage)
pred = predict(fit, data.frame(age=age.grid), se=TRUE)
pred2 = predict(fit2, data.frame(age=age.grid), se=TRUE)
plot(age, wage, xlim=agelims, cex=0.5, col='darkgrey')
title('Local Regression')
lines(age.grid, pred$fit, col='red', lwd=2)
lines(age.grid, pred2$fit, col='blue', lwd=2)
legend('topright', legend=c('Span = 0.2', 'Span = 0.5'), col=c('red', 'blue'), lty=1, lwd=2, cex=0.8)
# ---------------- 7.8.3 ----------------
gam1 = lm(wage~ns(year, 4)+ns(age, 5)+education, data=Wage)
# ---------------- 7.8.3 ----------------
library(gam)
library(gam)
install.packages("gam")
# ---------------- 7.8.3 ----------------
library(gam)
gam.m3 = lm(wage~s(year, 4)+s(age, 5)+education, data=Wage)
par(mfrow=c(1, 3))
plot(gam.m3, se=TRUE, col='blue')
warnings()
par(mfrow=c(1, 3))
plot(gam.m3, se=TRUE, col='blue')
gam.m3 = gam(wage~s(year, 4)+s(age, 5)+education, data=Wage)
par(mfrow=c(1, 3))
plot(gam.m3, se=TRUE, col='blue')
plot.gam(gam1, se=TRUE, col='red')
# ---------------- 7.8.3 ----------------
library(gam)
plot.gam(gam1, se=TRUE, col='red')
plot.Gam(gam1, se=TRUE, col='red')
plot.Gam(gam1, se=TRUE, col='red')
gam.m1 = gam(wage~s(age, 5)+education, data=Wage)
gam.m2 = gam(wage~year+s(age, 5)+education, data=Wage)
anova(gam.m1, gam.m2, gam.m3)
summary(gam.m3)
gam.m3 = gam(wage~s(year, 4)+s(age, 5)+education, data=Wage)
summary(gam.m3)
preds = predict(gam.m2, newdata=Wage)
gam.mo = gam(wage~s(year, df=4)+lo(age, span=0.7)+education, data=Wage)
gam.lo = gam(wage~s(year, df=4)+lo(age, span=0.7)+education, data=Wage)
rm(gam.mo)
plot.Gam(gam.lo, se=TRUE, col='green')
gam.lo.i = gam(wage~lo(year, age, span=0.7)+education, data=Wage)
gam.lo.i = gam(wage~lo(year, age, span=0.5)+education, data=Wage)
install.packages("akima")
plot(gam.lo.i)
gam.lr = gam(I(wage>250)~year+s(age, df=5)+education, data=Wage)
gam.lr = gam(I(wage>250)~year+s(age, df=5)+education, data=Wage, family='binomial')
par(mfrow=c(1, 3))
plot(gam.lr, se=TRUE, col='green')
table(eduation~I(wage>250))
table(eduation, I(wage>250))
table(education, I(wage>250))
gam.lr.s = gam(I(wage>250)~year+s(age, df=5)+education, data=Wage, family='binomial', subset=(education!='1. <HS Grad'))
plot(gam.lr.s, se=TRUE, col='green')
